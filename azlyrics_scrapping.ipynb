{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "favorite-prize",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "from billboard_scrapping import get_titles_and_artists_billboard, clean_artist, clean_song\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen, ProxyHandler, build_opener\n",
    "import time\n",
    "from whoosh.fields import Schema, TEXT, ID, STORED\n",
    "from whoosh.query import Every\n",
    "from whoosh.index import create_in, open_dir, exists_in\n",
    "from whoosh.qparser import QueryParser\n",
    "from shutil import rmtree\n",
    "import re\n",
    "from whoosh.query import Phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "thermal-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.azlyrics.com/'\n",
    "headers = {'User-Agent':'Mozilla/5.0'}\n",
    "\n",
    "def get_song_data_from_url(url):\n",
    "    try:\n",
    "        req = Request(url, headers=headers)\n",
    "        #req.set_proxy(proxy_host, 'http')\n",
    "        webpage = urlopen(req).read()\n",
    "        bs_webpage = BeautifulSoup(webpage,\"lxml\")\n",
    "    except:\n",
    "        print('exception at url: {}'.format(url))\n",
    "        return None\n",
    "        \n",
    "    title = bs_webpage.find_all('b')[1].text\n",
    "    artist = bs_webpage.find('h2').find('b').text\n",
    "    lyrics = bs_webpage.find_all('div', attrs={'class': None})[1].text\n",
    "    \n",
    "    try:\n",
    "        album = bs_webpage.find('div', class_='songinalbum_title').text\n",
    "    except AttributeError:\n",
    "        album = \"\"\n",
    "    \n",
    "    cleaning = Cleaning()\n",
    "    title = cleaning.title(title)\n",
    "    lyrics = cleaning.lyrics(lyrics)\n",
    "    full_lyrics = cleaning.full_lyrics(lyrics)\n",
    "    \n",
    "    if album==\"You May Also Like\":\n",
    "        album = \"\"\n",
    "    if album!=\"\":\n",
    "        album = cleaning.album(album)\n",
    "    \n",
    "    data = {\n",
    "        'title': title,\n",
    "        'artist': artist,\n",
    "        'lyrics': lyrics,\n",
    "        'full_lyrics': full_lyrics,\n",
    "        'album': album,\n",
    "        'url': url\n",
    "    }\n",
    "    \n",
    "    return data\n",
    "\n",
    "def create_schema():\n",
    "    schema = Schema(url=ID(),\n",
    "                    title=TEXT(stored=True),\n",
    "                    artist=TEXT(stored=True),\n",
    "                    full_lyrics=TEXT(stored=True, phrase=True),\n",
    "                    lyrics=TEXT(stored=True),\n",
    "                    album=TEXT(stored=True))\n",
    "    return schema\n",
    "\n",
    "def create_or_open_index(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "    if exists_in(directory):\n",
    "        index = open_dir(directory)\n",
    "    else:\n",
    "        schema = create_schema()\n",
    "        index = create_in(directory, schema)\n",
    "    return index\n",
    "\n",
    "def index_song(index, song_data):\n",
    "    writer = index.writer()\n",
    "    writer.add_document(url=u'{}'.format(song_data['url']),\n",
    "                        title=u'{}'.format(song_data['title']),\n",
    "                        artist=u'{}'.format(song_data['artist']),\n",
    "                        full_lyrics=u'{}'.format(song_data['full_lyrics']),\n",
    "                        lyrics=u'{}'.format(song_data['lyrics']),\n",
    "                        album=u'{}'.format(song_data['album']))\n",
    "    writer.commit(optimize=True)\n",
    "    \n",
    "def search_song_by_title(title, index):\n",
    "    results_list = list()\n",
    "    qp = QueryParser('title', schema=index.schema)\n",
    "    q = qp.parse(u\"{}\".format(title))\n",
    "    with index.searcher() as searcher:\n",
    "        results = searcher.search(q)\n",
    "        for result in results:\n",
    "            data = {\n",
    "                'title': result['title'],\n",
    "                'artist': result['artist'],\n",
    "                'full_lyrics': result['full_lyrics'],\n",
    "                'lyrics': result['lyrics'],\n",
    "                'album': result['album']\n",
    "            }\n",
    "            results_list.append(data)\n",
    "    return results_list\n",
    "\n",
    "def search_song_by_author(author, index):\n",
    "    results_list = list()\n",
    "    qp = QueryParser('author', schema=index.schema)\n",
    "    q = qp.parse(u\"{}\".format(title))\n",
    "    with index.searcher() as searcher:\n",
    "        results = searcher.search(q)\n",
    "        for result in results:\n",
    "            data = {\n",
    "                'title': result['title'],\n",
    "                'artist': result['artist'],\n",
    "                'full_lyrics': result['full_lyrics'],\n",
    "                'lyrics': result['lyrics'],\n",
    "                'album': result['album']\n",
    "            }\n",
    "            results_list.append(data)\n",
    "    return results_list\n",
    "\n",
    "def search_song_by_lyrics(terms, index):\n",
    "    results_list = list()\n",
    "    qp = QueryParser('full_lyrics', schema=index.schema)\n",
    "    q = qp.parse(u'\"{}\"'.format(terms))\n",
    "    \n",
    "    with index.searcher() as searcher:\n",
    "        results = searcher.search(q)\n",
    "        for result in results:\n",
    "            data = {\n",
    "                'title': result['title'],\n",
    "                'artist': result['artist'],\n",
    "                'full_lyrics': result['full_lyrics'],\n",
    "                'lyrics': result['lyrics'],\n",
    "                'album': result['album']\n",
    "            }\n",
    "            results_list.append(data)\n",
    "    return results_list\n",
    "\n",
    "def get_songs_urls_by_letter(letter, limit=None):\n",
    "\n",
    "    url = base_url+'{}.html'.format(letter)\n",
    "    final_url_list = list()\n",
    "    \n",
    "    def get_urls_by_letter(url):\n",
    "        req = Request(url)\n",
    "        webpage = urlopen(req).read()\n",
    "        bs_webpage = BeautifulSoup(webpage,\"lxml\")\n",
    "        divs = bs_webpage.find_all('div', class_='col-sm-6')\n",
    "        a_list = [i.find_all('a') for i in divs]\n",
    "        a_list = [base_url+i['href'] for j in a_list for i in j]\n",
    "        return a_list\n",
    "    \n",
    "    urls = get_urls_by_letter(url)\n",
    "    \n",
    "    for u in urls[:limit]:\n",
    "        req = Request(u)\n",
    "        webpage = urlopen(req).read()\n",
    "        bs_webpage = BeautifulSoup(webpage,\"lxml\")\n",
    "        divs = bs_webpage.find_all('div', class_='listalbum-item')\n",
    "        a_list = [i.find_all('a') for i in divs]\n",
    "        final_url_list.append([base_url+i['href'][3:] for j in a_list for i in j])\n",
    "        time.sleep(20)\n",
    "    \n",
    "    final_url_list = [i for j in final_url_list for i in j]\n",
    "    \n",
    "    return final_url_list\n",
    "\n",
    "def index_songs_by_letter(letter, index, limit=None):\n",
    "    urls = get_songs_urls_by_letter(letter, limit)\n",
    "    for u in urls:\n",
    "        song_data = get_song_data_from_url(u)\n",
    "        print(song_data['title'])\n",
    "        index_song(index, song_data)\n",
    "        time.sleep(15)\n",
    "        \n",
    "def index_songs_by_artist(artist, index):\n",
    "    letter = 19 if artist[:1] not in \"abcdefghijklmnopqrstuvwxyz\" else artist[:1]\n",
    "    url = base_url+\"{}/{}.html\".format(letter, clean_artist(artist))\n",
    "    \n",
    "    req = Request(url)\n",
    "    webpage = urlopen(req).read()\n",
    "    bs_webpage = BeautifulSoup(webpage,\"lxml\")\n",
    "    divs = bs_webpage.find_all('div', class_='listalbum-item')\n",
    "    a_list = [i.find_all('a') for i in divs]\n",
    "    final_url_list = [base_url+i['href'][3:] for j in a_list for i in j]\n",
    "    time.sleep(20)\n",
    "    \n",
    "    for u in final_url_list:\n",
    "        song_data = get_song_data_from_url(u)\n",
    "        print(song_data['title'])\n",
    "        index_song(index, song_data)\n",
    "        time.sleep(15)\n",
    "        \n",
    "def index_songs_by_billboard(number, index, limit=None):\n",
    "    song_artist_tuple = get_titles_and_artists_billboard(number)\n",
    "    \n",
    "    for song, artist in song_artist_tuple:\n",
    "        song = clean_song(song)\n",
    "        artist = clean_artist(artist)\n",
    "        url = base_url+'lyrics/{}/{}.html'.format(artist, song)\n",
    "        print(url)\n",
    "        song_data = get_song_data_from_url(url)\n",
    "        if song_data is None:\n",
    "            continue\n",
    "        print(song_data['title'])\n",
    "        index_song(index, song_data)\n",
    "        time.sleep(15)\n",
    "\n",
    "class Cleaning():\n",
    "    \n",
    "    def full_lyrics(self, lyrics):\n",
    "        lyrics = lyrics.split('\\r\\n')\n",
    "        lyrics = [i.replace('\\n', ' ')\n",
    "                  for i in lyrics if i not in ['\\n', '\\r', '\\n\\r', '\\r\\n', '']]\n",
    "        \n",
    "        lyrics = ', '.join(lyrics).replace(',', '').replace('.', '').lower()\n",
    "    \n",
    "        return lyrics\n",
    "    \n",
    "    def lyrics(self, lyrics):\n",
    "        lyrics = lyrics.replace('\\r', '').replace('\\n\\n', '\\n')\n",
    "        lyrics = lyrics[1:][:-1]\n",
    "        return lyrics\n",
    "    \n",
    "    def title(self, title):\n",
    "        title = title.replace('\"', '')\n",
    "        return title\n",
    "    \n",
    "    def album(self, album):\n",
    "        print(album)\n",
    "        if (album!=\"\"):\n",
    "            album = re.findall(r'\"([^\"]*)\"', album)[0]\n",
    "        return album"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "reflected-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo para una url de una cancion\n",
    "\n",
    "url=\"https://www.azlyrics.com/lyrics/pablocruise/islandwoman.html\"\n",
    "\n",
    "song_data = get_song_data_from_url(url)\n",
    "rmtree('./index')\n",
    "index = create_or_open_index('./index')\n",
    "index_song(index, song_data)\n",
    "results = search_song_by_title('Island', index)\n",
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo para urls por letra\n",
    "\n",
    "rmtree('./index')\n",
    "index = create_or_open_index('./index')\n",
    "for letter in \"abcdefghijklmnopqrstuvwxyz#\":\n",
    "    print(letter)\n",
    "    index_songs_by_letter(letter, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo para urls por billboard\n",
    "\n",
    "rmtree('./index')\n",
    "index = create_or_open_index('./index')\n",
    "index_songs_by_billboard(100, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "thousand-barcelona",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixtape: \"Esmeralda\" (2017)\n",
      "Alabame\n",
      "mixtape: \"Esmeralda\" (2017)\n",
      "Dafne\n",
      "mixtape: \"Esmeralda\" (2017)\n",
      "Daga\n",
      "mixtape: \"Esmeralda\" (2017)\n",
      "Esmeralda\n",
      "mixtape: \"Esmeralda\" (2017)\n",
      "Oreen Ishi\n",
      "mixtape: \"Esmeralda\" (2017)\n",
      "Sandía\n",
      "mixtape: \"Esmeralda\" (2017)\n",
      "Kun Fu\n",
      "EP: \"La Sandunguera\" (2018)\n",
      "Estoy Triste\n",
      "EP: \"La Sandunguera\" (2018)\n",
      "Hot Butter\n",
      "EP: \"La Sandunguera\" (2018)\n",
      "Gimme Some Pizza\n",
      "EP: \"La Sandunguera\" (2018)\n",
      "La Sandunguera\n",
      "EP: \"La Sandunguera\" (2018)\n",
      "Ma Time\n",
      "EP: \"La Sandunguera\" (2018)\n",
      "La Passione\n",
      "album: \"Calambre\" (2020)\n",
      "Celebré\n",
      "album: \"Calambre\" (2020)\n",
      "Sana Sana\n",
      "album: \"Calambre\" (2020)\n",
      "Buenos Aires\n",
      "album: \"Calambre\" (2020)\n",
      "Delito\n",
      "album: \"Calambre\" (2020)\n",
      "Sugga\n",
      "album: \"Calambre\" (2020)\n",
      "Trío\n",
      "album: \"Calambre\" (2020)\n",
      "Business Woman\n",
      "album: \"Calambre\" (2020)\n",
      "Llámame\n",
      "album: \"Calambre\" (2020)\n",
      "Amor Salvaje\n",
      "album: \"Calambre\" (2020)\n",
      "Arrorró\n",
      "album: \"Calambre\" (2020)\n",
      "Puro Veneno\n",
      "album: \"Calambre\" (2020)\n",
      "Agárrate\n",
      "Copa Glasé\n",
      "Corashe\n",
      "exception at url: https://www.azlyrics.com/ps://www.azlyrics.com/lyrics/bizarrap/nathypelusobzrpmusicsessions36.html\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1467b0261ed1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# rmtree('./index')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_or_open_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mindex_songs_by_artist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nathy peluso'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-130e31d9055c>\u001b[0m in \u001b[0;36mindex_songs_by_artist\u001b[0;34m(artist, index)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfinal_url_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0msong_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_song_data_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0mindex_song\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msong_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Ejemplo para urls por billboard\n",
    "\n",
    "# rmtree('./index')\n",
    "index = create_or_open_index('./index')\n",
    "index_songs_by_artist('nathy peluso', index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
